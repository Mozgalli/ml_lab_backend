# ğŸ§  ML Lab Backend

**Makine Ã–ÄŸrenimi ve Matematik Temelleri** iÃ§in kapsamlÄ± bir Python Backend projesi. Docker ile containerize edilmiÅŸ, FastAPI ile REST API, Jupyter Notebook entegrasyonu ve sÄ±fÄ±rdan yazÄ±lmÄ±ÅŸ ML algoritmalarÄ± iÃ§erir.

## ğŸ“‹ Ä°Ã§indekiler

- [Ã–zellikler](#-Ã¶zellikler)
- [Teknolojiler](#-teknolojiler)
- [Kurulum](#-kurulum)
- [KullanÄ±m](#-kullanÄ±m)
- [API Endpoints](#-api-endpoints)
- [Proje YapÄ±sÄ±](#-proje-yapÄ±sÄ±)
- [Ã–ÄŸrenme Yol HaritasÄ±](#-Ã¶ÄŸrenme-yol-haritasÄ±)
- [Algoritmalar](#-algoritmalar)

## âœ¨ Ã–zellikler

### ğŸ¯ Matematik Temelleri
- **Lineer Cebir**: Matris iÅŸlemleri, determinant, ters matris, eigenvalues/eigenvectors
- **Ä°statistik**: Ortalama, varyans, standart sapma, korelasyon, normalizasyon
- **Aktivasyon FonksiyonlarÄ±**: Sigmoid, ReLU, Tanh, Softmax
- **KayÄ±p FonksiyonlarÄ±**: MSE, MAE, Binary/Categorical Cross-Entropy
- **Optimizasyon**: Gradient Descent, Stochastic Gradient Descent

### ğŸ¤– Makine Ã–ÄŸrenimi AlgoritmalarÄ±
TÃ¼m algoritmalar **sÄ±fÄ±rdan Python ile yazÄ±lmÄ±ÅŸtÄ±r** (eÄŸitim amaÃ§lÄ±):

1. **Linear Regression** - SÃ¼rekli deÄŸer tahmini
2. **Logistic Regression** - Ä°kili sÄ±nÄ±flandÄ±rma
3. **K-Means** - KÃ¼meleme (clustering)
4. **K-Nearest Neighbors (KNN)** - SÄ±nÄ±flandÄ±rma ve regresyon
5. **Naive Bayes** - OlasÄ±lÄ±ksal sÄ±nÄ±flandÄ±rma

### ğŸ”§ Backend Ã–zellikleri
- **FastAPI**: Modern, hÄ±zlÄ± REST API
- **Docker**: Containerization ve kolay deployment
- **Jupyter Notebooks**: Ä°nteraktif Ã¶ÄŸrenme ve deney
- **Automatic Documentation**: Swagger UI ve ReDoc
- **Type Hints**: Tip gÃ¼venliÄŸi

## ğŸ›  Teknolojiler

```
Backend:
â”œâ”€â”€ Python 3.11
â”œâ”€â”€ FastAPI
â”œâ”€â”€ NumPy
â”œâ”€â”€ Scikit-learn
â”œâ”€â”€ Pandas
â”œâ”€â”€ Matplotlib & Seaborn
â””â”€â”€ Jupyter Notebook

Infrastructure:
â”œâ”€â”€ Docker
â”œâ”€â”€ Docker Compose
â””â”€â”€ Uvicorn ASGI Server

Optional:
â”œâ”€â”€ PyTorch
â””â”€â”€ TensorFlow
```

## ğŸ“¦ Kurulum

### Gereksinimler
- Docker & Docker Compose
- Git

### AdÄ±m 1: Projeyi KlonlayÄ±n
```bash
git clone <repository-url>
cd ml_lab_backend
```

### AdÄ±m 2: Environment DosyasÄ±nÄ± OluÅŸturun
```bash
cp .env.example .env
```

### AdÄ±m 3: Docker ile BaÅŸlatÄ±n
```bash
# TÃ¼m servisleri baÅŸlat
docker-compose up -d

# LoglarÄ± takip et
docker-compose logs -f
```

### AdÄ±m 4: Servislere EriÅŸin
- **Backend API**: http://localhost:8000
- **API Docs (Swagger)**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **Jupyter Notebook**: http://localhost:8888

## ğŸš€ KullanÄ±m

### 1. API ile Ä°nteraktif Ã‡alÄ±ÅŸma

**Swagger UI** Ã¼zerinden tÃ¼m endpoint'leri test edebilirsiniz:
```
http://localhost:8000/docs
```

### 2. Jupyter Notebook ile Ã–ÄŸrenme

```bash
# Jupyter container'Ä±na baÄŸlan
docker exec -it ml_lab_jupyter bash

# Veya tarayÄ±cÄ±dan direkt eriÅŸim
http://localhost:8888
```

### 3. Python Kodunda KullanÄ±m

```python
import numpy as np
from app.ml.algorithms import LinearRegressionFromScratch
from app.math_foundations.core import Statistics

# Veri oluÅŸtur
X = np.array([[1], [2], [3], [4], [5]])
y = np.array([2, 4, 6, 8, 10])

# Model oluÅŸtur ve eÄŸit
model = LinearRegressionFromScratch(learning_rate=0.01, n_iterations=1000)
model.fit(X, y, method="gradient_descent")

# Tahmin yap
predictions = model.predict(X)
print(f"RÂ² Score: {model.score(X, y)}")

# Ä°statistiksel analiz
stats = Statistics()
print(f"Mean: {stats.mean(y)}")
print(f"Std: {stats.standard_deviation(y)}")
```

## ğŸŒ API Endpoints

### Matematik Ä°ÅŸlemleri

#### VektÃ¶r Normu
```bash
POST /api/v1/math/vector/norm
{
  "vector": [3, 4]
}
# Response: {"norm": 5.0, "explanation": "..."}
```

#### Ä°Ã§ Ã‡arpÄ±m
```bash
POST /api/v1/math/vector/dot-product
{
  "vector1": [1, 2, 3],
  "vector2": [4, 5, 6]
}
# Response: {"dot_product": 32.0, "explanation": "..."}
```

#### Matris DeterminantÄ±
```bash
POST /api/v1/math/matrix/determinant
{
  "matrix": [[1, 2], [3, 4]]
}
# Response: {"determinant": -2.0, "explanation": "..."}
```

#### Eigenvalues ve Eigenvectors
```bash
POST /api/v1/math/matrix/eigenvalues
{
  "matrix": [[4, 2], [1, 3]]
}
# Response: {"eigenvalues": [...], "eigenvectors": [...]}
```

### Makine Ã–ÄŸrenimi

#### Linear Regression EÄŸitimi
```bash
POST /api/v1/ml/linear-regression/train
{
  "X": [[1], [2], [3], [4], [5]],
  "y": [2, 4, 6, 8, 10]
}
# Response: {"coefficients": [...], "r2_score": 1.0, ...}
```

#### Gradient Descent Demo
```bash
POST /api/v1/ml/gradient-descent
{
  "X": [[1], [2], [3]],
  "y": [2, 4, 6]
}
# Response: {"final_parameters": [...], "cost_history": [...]}
```

#### Algoritma Listesi
```bash
GET /api/v1/ml/algorithms
# Response: Liste of all available algorithms
```

## ğŸ“ Proje YapÄ±sÄ±

```
ml_lab_backend/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # FastAPI uygulamasÄ±
â”‚   â”‚
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ routes.py           # API endpoints
â”‚   â”‚
â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ algorithms.py       # ML algoritmalarÄ± (scratch)
â”‚   â”‚
â”‚   â””â”€â”€ math_foundations/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ core.py             # Matematik fonksiyonlarÄ±
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks
â”œâ”€â”€ data/                        # Dataset'ler
â”œâ”€â”€ models/                      # EÄŸitilmiÅŸ modeller
â”œâ”€â”€ tests/                       # Unit testler
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

## ğŸ“ Ã–ÄŸrenme Yol HaritasÄ±

### 1. Matematik Temelleri (Ã–nce Buradan BaÅŸlayÄ±n!)

#### Lineer Cebir
- [ ] VektÃ¶r iÅŸlemleri (toplama, Ã§arpma, norm)
- [ ] Matris Ã§arpÄ±mÄ± ve transpozu
- [ ] Determinant ve ters matris
- [ ] Eigenvalues ve eigenvectors
- [ ] SVD ve QR ayrÄ±ÅŸtÄ±rmasÄ±

#### Ä°statistik
- [ ] Merkezi eÄŸilim Ã¶lÃ§Ã¼leri (mean, median, mode)
- [ ] DaÄŸÄ±lÄ±m Ã¶lÃ§Ã¼leri (variance, std)
- [ ] Kovaryans ve korelasyon
- [ ] Normalizasyon teknikleri

#### KalkÃ¼lÃ¼s
- [ ] TÃ¼rev ve gradyan
- [ ] KÄ±smi tÃ¼revler
- [ ] Chain rule
- [ ] Optimizasyon (gradient descent)

### 2. Makine Ã–ÄŸrenimi AlgoritmalarÄ±

#### Supervised Learning
1. **Linear Regression** â­ BaÅŸlangÄ±Ã§
   - Normal equation
   - Gradient descent
   - Overfitting ve regularization
   
2. **Logistic Regression** â­â­
   - Sigmoid fonksiyonu
   - Binary classification
   - Decision boundary
   
3. **K-Nearest Neighbors** â­â­
   - Distance metrics
   - K deÄŸeri seÃ§imi
   - Classification vs Regression

4. **Naive Bayes** â­â­
   - Bayes teoremi
   - Probability distributions
   - Text classification

#### Unsupervised Learning
1. **K-Means Clustering** â­â­
   - Centroid initialization
   - Convergence
   - Elbow method

### 3. Ä°leri Seviye Konular
- Neural Networks
- Deep Learning
- Ensemble Methods
- Dimensionality Reduction (PCA)

## ğŸ§ª Algoritmalar

### Linear Regression
```python
from app.ml.algorithms import LinearRegressionFromScratch

# Model oluÅŸtur
model = LinearRegressionFromScratch(learning_rate=0.01, n_iterations=1000)

# EÄŸit (iki yÃ¶ntem)
model.fit(X_train, y_train, method="gradient_descent")
# veya
model.fit(X_train, y_train, method="normal_equation")

# Tahmin
predictions = model.predict(X_test)

# DeÄŸerlendirme
r2 = model.score(X_test, y_test)
```

### Logistic Regression
```python
from app.ml.algorithms import LogisticRegressionFromScratch

model = LogisticRegressionFromScratch(learning_rate=0.01, n_iterations=1000)
model.fit(X_train, y_train)

# OlasÄ±lÄ±k tahmini
probabilities = model.predict_proba(X_test)

# SÄ±nÄ±f tahmini
predictions = model.predict(X_test, threshold=0.5)

# Accuracy
accuracy = model.score(X_test, y_test)
```

### K-Means
```python
from app.ml.algorithms import KMeansFromScratch

model = KMeansFromScratch(n_clusters=3, max_iters=100, random_state=42)
model.fit(X)

# KÃ¼me etiketleri
labels = model.labels

# Centroid'ler
centroids = model.centroids

# Yeni veri iÃ§in tahmin
new_labels = model.predict(X_new)
```

### K-Nearest Neighbors
```python
from app.ml.algorithms import KNNFromScratch

model = KNNFromScratch(k=5)
model.fit(X_train, y_train)

predictions = model.predict(X_test)
```

### Naive Bayes
```python
from app.ml.algorithms import NaiveBayesFromScratch

model = NaiveBayesFromScratch()
model.fit(X_train, y_train)

predictions = model.predict(X_test)
```

## ğŸ“Š Ã–rnek KullanÄ±m SenaryolarÄ±

### 1. Ev Fiyat Tahmini (Linear Regression)
```python
# Veri: [alan, oda_sayisi, yaÅŸ] -> fiyat
X = np.array([
    [100, 3, 10],
    [150, 4, 5],
    [80, 2, 15],
    [200, 5, 2]
])
y = np.array([250000, 400000, 180000, 550000])

model = LinearRegressionFromScratch()
model.fit(X, y)

# Yeni ev iÃ§in tahmin
new_house = np.array([[120, 3, 8]])
predicted_price = model.predict(new_house)
```

### 2. Email Spam Tespiti (Logistic Regression)
```python
# Feature'lar (kelime frekanslarÄ±, bÃ¼yÃ¼k harf oranÄ±, vs.)
X_emails = ...  # Email feature'larÄ±
y_spam = ...    # 0: normal, 1: spam

model = LogisticRegressionFromScratch()
model.fit(X_emails, y_spam)

# Yeni email test et
new_email_features = ...
spam_probability = model.predict_proba(new_email_features)
```

### 3. MÃ¼ÅŸteri Segmentasyonu (K-Means)
```python
# MÃ¼ÅŸteri Ã¶zellikleri: [yaÅŸ, gelir, harcama]
X_customers = np.array([...])

model = KMeansFromScratch(n_clusters=4)
model.fit(X_customers)

# Her mÃ¼ÅŸterinin segmenti
segments = model.labels
```

## ğŸ³ Docker KomutlarÄ±

```bash
# Servisleri baÅŸlat
docker-compose up -d

# LoglarÄ± gÃ¶rÃ¼ntÃ¼le
docker-compose logs -f ml_backend

# Backend container'a baÄŸlan
docker exec -it ml_lab_backend bash

# Jupyter container'a baÄŸlan
docker exec -it ml_lab_jupyter bash

# Servisleri durdur
docker-compose down

# Servisleri yeniden build et
docker-compose up --build -d

# TÃ¼m verileri sil (dikkat!)
docker-compose down -v
```

## ğŸ§ª Test

```bash
# Docker iÃ§inde test Ã§alÄ±ÅŸtÄ±r
docker exec -it ml_lab_backend pytest

# Veya local
pytest tests/
```

## ğŸ“š Kaynaklar ve Ã–ÄŸrenme Materyalleri

### Kitaplar
- "Pattern Recognition and Machine Learning" - Christopher Bishop
- "The Elements of Statistical Learning" - Hastie, Tibshirani, Friedman
- "Deep Learning" - Ian Goodfellow

### Online Kurslar
- Andrew Ng - Machine Learning (Coursera)
- Fast.ai - Practical Deep Learning
- MIT 18.06 - Linear Algebra

### Matematiksel FormÃ¼ller

#### Gradient Descent
$$\theta_{t+1} = \theta_t - \alpha \nabla J(\theta_t)$$

#### Linear Regression (Normal Equation)
$$\theta = (X^TX)^{-1}X^Ty$$

#### Sigmoid Function
$$\sigma(x) = \frac{1}{1 + e^{-x}}$$

#### Mean Squared Error
$$MSE = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2$$

## ğŸ¤ KatkÄ±da Bulunma

Projeye katkÄ±da bulunmak isterseniz:
1. Fork yapÄ±n
2. Feature branch oluÅŸturun (`git checkout -b feature/amazing-feature`)
3. DeÄŸiÅŸikliklerinizi commit edin (`git commit -m 'Add amazing feature'`)
4. Branch'inizi push edin (`git push origin feature/amazing-feature`)
5. Pull Request aÃ§Ä±n

## ğŸ“ Lisans

Bu proje eÄŸitim amaÃ§lÄ±dÄ±r ve aÃ§Ä±k kaynaklÄ±dÄ±r.

## ğŸ’¡ Sorular ve Destek

SorularÄ±nÄ±z iÃ§in:
- Issue aÃ§Ä±n
- Discussions kullanÄ±n
- Email: [your-email]

## ğŸ¯ Roadmap

- [ ] Daha fazla algoritma ekle (Decision Trees, Random Forest)
- [ ] Neural Network implementasyonu
- [ ] Web UI ekle (React frontend)
- [ ] Model persistence (model kaydetme/yÃ¼kleme)
- [ ] Daha fazla Ã¶rnek dataset
- [ ] Video tutorial serisi
- [ ] Interactive visualizations

---

**Happy Learning! ğŸš€ğŸ§ **

*Makine Ã¶ÄŸrenimi yolculuÄŸunuzda baÅŸarÄ±lar dileriz!*
